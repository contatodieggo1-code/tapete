# Robots.txt para Tapetes Higiênicos Premium para Pets
# Última atualização: 15 de janeiro de 2024

User-agent: *
Allow: /
Allow: /images/

# Sitemap
Sitemap: https://tapeteshigienicos.com.br/sitemap.xml

# Bloquear arquivos temporários e de sistema
Disallow: /api/
Disallow: /_next/
Disallow: /tmp/
Disallow: /temp/
Disallow: /private/
Disallow: /config/

# Bloquear páginas de busca e filtros (se existirem)
Disallow: /search?
Disallow: /filter?
Disallow: /sort?

# Bloquear parâmetros de rastreamento
Disallow: /*?utm_*
Disallow: /*?fbclid*
Disallow: /*?gclid*
Disallow: /*?_ga*

# Taxa de rastreamento (Crawl-delay)
Crawl-delay: 1

# User-agent específicos para buscadores populares

# Google
User-agent: Googlebot
Allow: /
Crawl-delay: 0

# Googlebot-Image
User-agent: Googlebot-Image
Allow: /images/

# Bing
User-agent: bingbot
Allow: /
Crawl-delay: 1

# Yahoo
User-agent: Slurp
Allow: /
Crawl-delay: 1

# Baidu
User-agent: Baiduspider
Allow: /
Crawl-delay: 2

# Yandex
User-agent: YandexBot
Allow: /
Crawl-delay: 1

# DuckDuckGo
User-agent: DuckDuckBot
Allow: /
Crawl-delay: 1

# Bot específicos para imagens
User-agent: Pinterestbot
Allow: /images/

User-agent: FacebookBot
Allow: /
Allow: /images/

# Bloquear bots maliciosos
User-agent: SemrushBot
Disallow: /

User-agent: AhrefsBot
Disallow: /

User-agent: MJ12bot
Disallow: /

User-agent: DotBot
Disallow: /

# User-agent para ferramentas de SEO (permitir com moderação)
User-agent: Screaming Frog SEO Spider
Crawl-delay: 2

User-agent: Sitebulb
Crawl-delay: 2

# Informações adicionais para os motores de busca

# Host (para SEO internacional)
Host: https://tapeteshigienicos.com.br

# Limpeza de URL limpa
Clean-param: utm_source&utm_medium&utm_campaign&utm_content&utm_term /
Clean-param: fbclid /
Clean-param: gclid /
Clean-param: _ga /

# Geotargeting
# Para sites brasileiros, isso ajuda no posicionamento local